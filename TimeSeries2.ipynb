{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1nlPdyfpNDZu0DRiL1v5sZOg94ZsoQxm6","authorship_tag":"ABX9TyPKrMP9Qpd1+3bo6SlvJc4R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 1. ARIMA 모델링 – 쉽게 풀어보기\n","\n","1. **ARIMA란?**  \n","   - **AR**(AutoRegressive): 과거 값들이 현재 값에 영향을 준다고 가정  \n","   - **I**(Integrated): 차분(differencing)으로 시계열을 안정화  \n","   - **MA**(Moving Average): 과거 예측 오차들이 현재에 반영됨  \n","\n","2. **(1,1,1) 의미**  \n","   - **p=1**: 바로 전날 가격 하나만 자기회귀(AR)로 사용  \n","   - **d=1**: ‘하루 차분’ → `today − yesterday` 값을 예측 대상으로 삼아 시계열을 정상(stationary)으로 만듦  \n","   - **q=1**: 가장 최근 예측 오차 하나(MA)를 모델에 포함  \n","\n","  ### **2-1. 차분의 개념**  \n","- **차분(1차 차분)**이란 “오늘값 – 어제값”을 계산하는 것  \n","- 이렇게 하면 **추세가 제거**되어,  \n","  - 원래 데이터가 꾸준히 상승했다면  \n","  - 차분된 데이터는 오르내림(증가량)만 남아 평탄해집니다.\n","\n","---\n","\n","  ### 2-2. **간단한 숫자 예시**\n","\n","  | t (일) | 원본 가격 \\(y_t\\) | 1차 차분 \\(y_t - y_{t-1}\\) |\n","  |-------|------------------|-----------------------------|\n","  | 1     | 10               | –                           |\n","  | 2     | 12               | \\(12 - 10 = 2\\)             |\n","  | 3     | 15               | \\(15 - 12 = 3\\)             |\n","  | 4     | 20               | \\(20 - 15 = 5\\)             |\n","  | 5     | 27               | \\(27 - 20 = 7\\)             |\n","\n","- **원본**: 10 → 12 → 15 → 20 → 27 (계속 증가하는 추세)  \n","- **차분**: 2, 3, 5, 7 (증가량만 남음)  \n","  - 이 차분 시퀀스는 더 이상 “꾸준히 오르는” 추세가 없고, **평균 변화량** 주위로 움직입니다.\n","\n","\n","3. **학습 & 예측 흐름**  \n","   - 훈련: 과거 3개월 − 마지막 20일 구간까지  \n","   - 모델은 “차분된 시계열”을 AR(1) + MA(1) 공식으로 학습  \n","   - 예측: 남은 20일(테스트 구간)에 대해, 하루씩 차분된 예측값을 원래 수준으로 복원해 출력  \n","\n","4. **장·단점 요약**  \n","   - 장점: 시계열 특성(추세·자기상관·노이즈) 직접 모델링  \n","   - 단점: 비선형 패턴이나 외부 변수(거래량·뉴스)는 반영 못 함  \n","\n","---\n","\n","## 2. XGBoost로 예측하기 – 단계별 설명\n","\n","1. **왜 XGBoost?**  \n","   - 트리 기반 앙상블 기법으로,  \n","   - 비선형 관계나 복잡한 상호작용을 잘 잡아냅니다.\n","\n","2. **Lag & Rolling 피처(Feature) 만들기**  \n","   - `lag1`~`lag5`: 1 ~ 5일 전 종가를 새로운 컬럼으로 추가  \n","     - “어제·2일 전·…·5일 전” 가격이 오늘 가격에 주는 영향을 학습  \n","   - `roll_mean5`: 과거 5일 종가 평균  \n","     - 최근 5일의 ‘전반적 흐름’을 모델에 알려 줌  \n","\n","3. **학습 & 예측 과정**  \n","   - 훈련: lag/rolling 특성과 종가를 이용해 XGBoost 회귀 모델 학습  \n","   - 예측: 테스트 20일 구간의 피처를 입력 → `predict()`로 종가 반환  \n","\n","4. **주요 하이퍼파라미터**  \n","   - `n_estimators=100`: 트리 100개 사용  \n","   - `learning_rate=0.1`: 각 트리가 기여하는 정도  \n","   - **돋보기**: 트리 수나 학습률을 늘리면 → 과적합↑/속도↓, 줄이면 → 과소적합↑/속도↑  \n","\n","5. **장·단점**  \n","   - 장점: 외부 변수·비선형성 반영, 강력한 예측 성능  \n","   - 단점: 시계열 순서를 직접 반영하지 않으니 lag 같은 전처리가 필수  \n","\n","---\n"],"metadata":{"id":"vGm_31v5vbw8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8JI34z8evbHM"},"outputs":[],"source":["import pandas as pd\n","import yfinance as yf\n","\n","# 1) 삼성전자(005930.KS) 최근 3개월 일별 주가 가져오기\n","ticker = '005930.KS'\n","data = yf.download(ticker, period='3mo', interval='1d')\n","data = data[['Open','High','Low','Close','Volume']]\n","data.to_csv('/content/drive/MyDrive/AI/Data/samsung_3mo.csv')\n","\n","# 2) ARIMA 모델링\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","# 종가만 사용\n","ts = data['Close']\n","train_ts = ts.iloc[:-20]\n","test_ts = ts.iloc[-20:]\n","\n","# 단순 SARIMAX(1,1,1)\n","model_arima = SARIMAX(train_ts, order=(1,1,1), enforce_stationarity=False, enforce_invertibility=False)\n","res_arima = model_arima.fit(disp=False)\n","n_train = len(train_ts)\n","n_test  = len(test_ts)\n","pred_arima = res_arima.predict(start=n_train, end=n_train+n_test-1, typ='levels')\n","print(pred_arima)\n","\n","\n","# 3) XGBoost 모델링\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.metrics import mean_squared_error\n","import xgboost as xgb\n","\n","# Feature engineering: lag features\n","df_xgb = data[['Close']].copy()\n","for lag in range(1,6):\n","    df_xgb[f'lag{lag}'] = df_xgb['Close'].shift(lag)\n","df_xgb['roll_mean5'] = df_xgb['Close'].rolling(5).mean()\n","df_xgb.dropna(inplace=True)\n","\n","X = df_xgb.drop('Close', axis=1)\n","y = df_xgb['Close']\n","# split\n","train_X, test_X = X.iloc[:-20], X.iloc[-20:]\n","train_y, test_y = y.iloc[:-20], y.iloc[-20:]\n","\n","xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=0)\n","xgb_model.fit(train_X, train_y)\n","pred_xgb = xgb_model.predict(test_X)\n","print(pred_xgb)"]},{"cell_type":"code","source":["import numpy as np\n","import itertools\n","import statsmodels.api as sm\n","\n","p = q = range(0, 4)\n","d = [0, 1]\n","best_aic = np.inf\n","best_order = None\n","\n","for order in itertools.product(p, d, q):\n","  try:\n","    model = sm.tsa.SARIMAX(ts, order=order)\n","    res = model.fit(disp=False)\n","    if res.aic < best_aic:\n","      best_aic = res.aic\n","      best_order = order\n","  except:\n","    continue\n","\n","print(\"Best ARIMA order:\", best_order, \"AIC:\", best_aic)"],"metadata":{"id":"Nd-U-_CixF0y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pmdarima import auto_arima\n","auto_model = auto_arima(ts, seasonal=False, stepwise=True,\n","                        max_p=5, max_q=5, d=None)\n","print(auto_model.order)"],"metadata":{"id":"a1T0GkWaxXEm"},"execution_count":null,"outputs":[]}]}